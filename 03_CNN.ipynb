{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "885c0795-8ad4-4148-b9f0-0118d33ea716",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision as torchvision\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from torch.nn.functional import cross_entropy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from torchmetrics import Accuracy\n",
    "from pytorch_lightning import LightningModule, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6c65002-d997-4c7d-ae6d-583532f46f97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# unzip files\n",
    "# !unzip \"/home/jovyan/work/Assignment_3/files/Test-20241113T152628Z-001.zip\" -d \"./files\"\n",
    "# !unzip \"/home/jovyan/work/Assignment_3/files/Training-20241113T155003Z-001.zip\" -d \"./files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ce48c2f-81e4-46f4-b3c8-155d4416818b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Exercise 4: Data Loading\n",
    "class DataLoading:\n",
    "    def __init__(self):\n",
    "        self.filePath = \"./files/\"\n",
    "        self.batch_size = 16\n",
    "\n",
    "    def load_data(self):\n",
    "\n",
    "        train_set = torchvision.datasets.ImageFolder(root=self.filePath + \"Training\",\n",
    "                                                     transform=torchvision.transforms.Compose(\n",
    "                                                         [torchvision.transforms.ToTensor(),\n",
    "                                                          torchvision.transforms.Resize((100, 100))]))\n",
    "\n",
    "        test_set = torchvision.datasets.ImageFolder(root=self.filePath + \"Test\",\n",
    "                                                    transform=torchvision.transforms.Compose(\n",
    "                                                        [torchvision.transforms.ToTensor(),\n",
    "                                                         torchvision.transforms.Resize((100, 100))]))\n",
    "        trainlength = round(0.8 * len(train_set))\n",
    "        vallength = round(0.2 * len(train_set))\n",
    "        train_set, val_set = random_split(train_set, [trainlength, vallength])\n",
    "\n",
    "        train_loader = DataLoader(train_set, batch_size=self.batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_set, batch_size=self.batch_size, shuffle=False)\n",
    "        test_loader = DataLoader(test_set, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "        return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8ee3b09-2f14-4d00-b9b0-8c04e59cd375",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | layer1    | Sequential         | 1.2 K \n",
      "1 | layer2    | Sequential         | 4.7 K \n",
      "2 | layer3    | Sequential         | 18.6 K\n",
      "3 | layer4    | Sequential         | 74.1 K\n",
      "4 | flatten   | Flatten            | 0     \n",
      "5 | fc        | Sequential         | 558 K \n",
      "6 | train_acc | MulticlassAccuracy | 0     \n",
      "7 | val_acc   | MulticlassAccuracy | 0     \n",
      "8 | test_acc  | MulticlassAccuracy | 0     \n",
      "-------------------------------------------------\n",
      "657 K     Trainable params\n",
      "0         Non-trainable params\n",
      "657 K     Total params\n",
      "2.630     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca0c8cbf79c4e5cab706b31efca7166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Train Accuracy: 0.7385\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Accuracy: 0.9452\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Train Accuracy: 0.9753\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Train Accuracy: 0.9701\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Train Accuracy: 0.9681\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Accuracy: 0.9714\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Train Accuracy: 0.9728\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Train Accuracy: 0.9716\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Train Accuracy: 0.9743\n",
      "Max Train Accuracy Achieved: 0.9753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at logs/lightning_logs/version_63/checkpoints/epoch=8-step=2286.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at logs/lightning_logs/version_63/checkpoints/epoch=8-step=2286.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e0355b02e14b0fa43497d76875da07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       avg_test_acc        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9999999403953552     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       avg_test_loss       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.002864023670554161    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            1.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.002882543718442321    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      avg_test_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9999999403953552    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      avg_test_loss      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.002864023670554161   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.002882543718442321   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class PLANTSCNN(pl.LightningModule):\n",
    "# Exercise 1: Convolutional Neural Network Architecture Definition\n",
    "    def __init__(self):\n",
    "        super(PLANTSCNN, self).__init__()\n",
    "        # Layer block 1\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(5, 5), stride=1, padding=\"same\"),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        )\n",
    "\n",
    "        # Layer block 2\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), stride=1, padding=\"same\"),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        )\n",
    "\n",
    "        # Layer block 3\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        )\n",
    "\n",
    "        # Layer block 4\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), stride=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        )\n",
    "\n",
    "        # Flatten layer\n",
    "        self.flatten = nn.Flatten()\n",
    "        '''\n",
    "        For the answer, of why the fully connected layer needs an Input of 128*4*4 comes here the calculation of the convolutional layer output sizes:\n",
    "        \n",
    "        Output shape layer1:\n",
    "        Where:\n",
    "            HW: Input height and width\n",
    "            K: Kernel size\n",
    "            S: Stride\n",
    "            P: Padding\n",
    "            MP: MaxPool\n",
    "\n",
    "            For \"same\" padding:\n",
    "            P = K/2\n",
    "            \n",
    "           W & H = ((HW - K + 2*P/S)+1)/MP\n",
    "           \n",
    "        W & H = ((100-5+2*2/1)+1)/2 = 50\n",
    "        (16, 50, 50)\n",
    "        \n",
    "        Output shape layer2:\n",
    "        W & H = ((50-3+2*1/1)+1)/2 = 25\n",
    "        (32, 25, 25)\n",
    "        \n",
    "        Output shape layer3:\n",
    "        W & H = ((25-3+2*0/1)+1)/2 = 11.5 ~ 11\n",
    "        (64, 11, 11)\n",
    "        \n",
    "        Output shape layer4:\n",
    "        W & H = ((11-3+2*0/1)+1)/2 = 4.5 ~ 4\n",
    "        (128, 4, 4)\n",
    "        \n",
    "        Now the output size of the last conv layer is (128, 4, 4). Those will be flattend to a 1d Vecoter for the input of the\n",
    "        Fully connected layer 128*4*4 = 2048. So the Input size for the fully connected layer is 2048.\n",
    "        '''\n",
    "\n",
    "        # Fully connected layer block\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 * 4 * 4, 256),  # Adjust if input size differs\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "        \n",
    "        self.train_acc = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.val_acc = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.test_acc = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.train_acc_history = []\n",
    "        self.test_step_outputs = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "# Exercise 2: Optimizer\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr=0.01)\n",
    "        lr_scheduler = StepLR(optimizer=optimizer, step_size=1)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "        \n",
    "# Exercise 3: Training, Validation and Test Step\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = cross_entropy(y_hat, y)\n",
    "        \n",
    "        # Update train accuracy\n",
    "        self.train_acc(y_hat, y)\n",
    "        \n",
    "        # Log training loss and accuracy\n",
    "        self.log(\"train_loss\", loss, on_step=True)\n",
    "        self.log(\"train_acc\", self.train_acc, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        self.train_acc(y_hat, y)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        # Compute and log the train accuracy for the epoch\n",
    "        train_acc_epoch = self.train_acc.compute()\n",
    "        # Store the accuracy in the history list\n",
    "        self.train_acc_history.append(train_acc_epoch.item())\n",
    "        print(f\"Epoch {self.current_epoch} - Train Accuracy: {train_acc_epoch:.4f}\")\n",
    "        # Reset metric for the next epoch\n",
    "        self.train_acc.reset()\n",
    "        \n",
    "    def on_train_end(self):\n",
    "        # Log the max train accuracy achieved\n",
    "        max_train_acc = max(self.train_acc_history)\n",
    "        print(f\"Max Train Accuracy Achieved: {max_train_acc:.4f}\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        val_loss = cross_entropy(y_hat, y)\n",
    "        self.val_acc(y_hat, y)\n",
    "        self.log(\"val_loss\", val_loss, on_step=False, on_epoch=True)\n",
    "        self.log(\"val_acc\", self.val_acc, on_epoch=True)\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        test_loss = cross_entropy(y_hat, y)\n",
    "        self.log(\"test_loss\", test_loss, on_step=False, on_epoch=True)\n",
    "        self.log(\"test_acc\", self.test_acc, on_step=False, on_epoch=True)\n",
    "        self.test_step_outputs.append({\"test_loss\": test_loss, \"test_acc\": self.test_acc(y_hat, y)})\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        avg_loss = torch.stack([x[\"test_loss\"] for x in self.test_step_outputs]).mean()\n",
    "        avg_acc = torch.stack([x[\"test_acc\"] for x in self.test_step_outputs]).mean()\n",
    "        self.log(\"avg_test_loss\", avg_loss)\n",
    "        self.log(\"avg_test_acc\", avg_acc)\n",
    "        self.test_step_outputs.clear()  # Clear the outputs after logging\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Main function of script\n",
    "    num_epochs = 200\n",
    "    \n",
    "    data_load = DataLoading()\n",
    "    train_loader, val_loader, test_loader = data_load.load_data()\n",
    "    \n",
    "# Exercise 5: Training and Evaluation\n",
    "    model = PLANTSCNN()\n",
    "\n",
    "    tb_logger = pl_loggers.TensorBoardLogger(save_dir=\"logs/\")\n",
    "\n",
    "    trainer = Trainer(log_every_n_steps=10, max_epochs=num_epochs, logger=tb_logger,\n",
    "                         callbacks=EarlyStopping(monitor=\"val_loss\", patience=5))\n",
    "\n",
    "    trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "    trainer.test(ckpt_path=\"best\", dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acac6c91-b203-4335-8fd1-75aab69a5394",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Exercise 6: Results\n",
    "# Train Accuracy: 97.53%\n",
    "# Test Accuracy: 99.9%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
